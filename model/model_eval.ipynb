{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1787e95",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66523412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d9db5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and components\n",
    "model_filename = 'xgboost_model.pkl'\n",
    "scaler_filename = 'scaler.pkl'\n",
    "metadata_filename = 'model_metadata.json'\n",
    "\n",
    "def load_model_components():\n",
    "    \"\"\"Load the trained model, scaler, and metadata\"\"\"\n",
    "    model = joblib.load(model_filename)\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "    \n",
    "    with open(metadata_filename, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    return model, scaler, metadata\n",
    "\n",
    "model_loaded, scaler_loaded, metadata_loaded = load_model_components()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "# random sampling\n",
    "def get_sample_datapoint():\n",
    "    random_index = np.random.randint(0, len(df))\n",
    "    sample_data = df.iloc[random_index].to_dict()  # Get first row as dictionary\n",
    "    return sample_data\n",
    "\n",
    "def get_sample_json_data():\n",
    "    sample_data = get_sample_datapoint()\n",
    "    sample_json = json.dumps(sample_data, indent=2)\n",
    "    return sample_json, sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77174c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(json_data, model, scaler, metadata):\n",
    "    \"\"\"\n",
    "    Evaluate model on a single datapoint coming from JSON format\n",
    "    \n",
    "    Args:\n",
    "        json_data: Dictionary or JSON string containing the datapoint\n",
    "        model: Trained XGBoost model\n",
    "        scaler: Fitted StandardScaler\n",
    "        metadata: Model metadata containing feature names and class mapping\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    # Convert JSON string to dict if needed\n",
    "    if isinstance(json_data, str):\n",
    "        data = json.loads(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "    \n",
    "    # Extract features (exclude target if present)\n",
    "    feature_names = metadata['feature_names']\n",
    "    X_sample = np.array([data[feat] for feat in feature_names]).reshape(1, -1)\n",
    "    \n",
    "    # Scale the features\n",
    "    X_sample_scaled = scaler.transform(X_sample)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_sample_scaled)[0]\n",
    "    prediction_proba = model.predict_proba(X_sample_scaled)[0]\n",
    "    \n",
    "    # Convert prediction back to original class labels\n",
    "    class_mapping = json.loads(metadata['class_mapping'])\n",
    "    reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
    "    original_prediction = reverse_mapping[prediction]\n",
    "    \n",
    "    # Get class probabilities for original classes\n",
    "    class_labels = sorted(class_mapping.keys())\n",
    "    proba_dict = {class_labels[i]: float(prediction_proba[i]) for i in range(len(class_labels))}\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': int(original_prediction),\n",
    "        'prediction_probabilities': proba_dict,\n",
    "        'confidence': float(max(prediction_proba))\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb3e92d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with JSON string input:\n",
      "Result from JSON string: {'predicted_class': 1, 'prediction_probabilities': {'1': 0.32749372720718384, '2': 0.16105243563652039, '3': 0.24216479063034058, '4': 0.15721692144870758, '5': 0.1120721697807312}, 'confidence': 0.32749372720718384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/r1m9n/miniforge3/envs/sft/lib/python3.14/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# example request in JSON string (as would come from API)\n",
    "sample_json_string, sample_data = get_sample_json_data()\n",
    "print(\"Testing with JSON string input:\")\n",
    "result_json = evaluate_model(sample_json_string, model_loaded, scaler_loaded, metadata_loaded)\n",
    "print(f\"Result from JSON string: {result_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46eb631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
